# README
## 白盒攻击
<ul>
  <li>
  模型：<br>  
  模型共有5个隐藏层。<br>
  第一个隐藏层：5x5的卷积层，深度为32，步长为1，padding使得图像尺寸不变；<br>
  第二个隐藏层：2x2的max pooling层，步长为2，图像尺寸变为原来1/4；<br>
  第三个隐藏层：5x5的卷基层，深度为64，步长为1，图像尺寸保持不变；<br>
  第四个隐藏层：2x2的max pooling层，步长为2，图像尺寸变为原来1/4；<br>
  第五个隐藏层：1024个神经元的全连接层，采用0.4的dropout。<br>
  模型代码：model.py
  </li>
  <li>
  测试集上的正确率：0.91480
  </li>
  <li>
  方法：通过模型对要冒充的类型求loss，并对x求导，将梯度乘一个常数加到x上，循环1000轮。具体参考代码w_attack.py。
  </li>
  <li>
  攻击成功率：0.646
  </li>
  <li>
  成功攻击样例展示，第一行为原图，第二行为攻击之后的图像。<br>
    <p><img src="https://img-blog.csdnimg.cn/20191102143738960.png"></p>  
    <p><img src="https://img-blog.csdnimg.cn/2019110214380492.png"></p>
  </li>
</ul>
## 黑盒攻击
<ul>
  <li> 采用迁移攻击方法：模拟待攻击模型得到一个傀儡模型，对傀儡模型进行白盒攻击，用改动后的数据对待攻击模型进行黑盒攻击。具体来说，我先运行test_traindata.py获得待攻击模型在训练集上的预测值，然后将预测值作为ground true在train_dummy.py里利用第一步白盒攻击的模型训练出一个傀儡模型。然后用dummy_attack.py对傀儡模型进行白盒攻击，存储改变后的图像，用b_attack.py对待攻击模型进行黑盒攻击。</li>
  <li>攻击成功率：0.258</li>
  <li>
  成功攻击样例展示，第一行为原图，第二行为攻击之后的图像。 <br>
    <p><img src="https://img-blog.csdnimg.cn/20191102143818514.png"></p>  
    <p><img src="https://img-blog.csdnimg.cn/20191102143847573.png"></p> 
  </li>
</ul>

## 对抗训练
<ul>
<li> 对抗训练要求，取出一部分被白盒/黑盒攻击过的样本，将这些样本加到原模型的训练集中进行训练之后再对模型进行白盒/黑盒攻击。</li>
<li> 白盒攻击对抗训练之后模型在test集上的正确率：0.91390<br>
    黑盒攻击对抗训练之后模型在test集上的正确率：0.91230
</li>
<li> 白盒攻击在新分类器上的攻击成功率：0.525</li>
<li> 白盒攻击成功攻击样例展示，第一行为原图，第二行为攻击之后的图像。<br>
    <p><img src="https://img-blog.csdnimg.cn/20191102143900629.png"></p>  
    <p><img src="https://img-blog.csdnimg.cn/20191102143910338.png"></p> </li>
<li> 黑盒攻击在新分类器上的攻击成功率：0.003。（这里的黑盒攻击攻击的是第一步的模型，没有强化训练时成功率也只有0.007。）</li>
<li> 黑盒攻击成功攻击样例展示，第一行为原图，第二行为攻击之后的图像。<br>
    <p><img src="https://img-blog.csdnimg.cn/20191102143923416.png"></p>  
    <p><img src="https://img-blog.csdnimg.cn/20191102143945555.png"></p> </li>
</ul>
